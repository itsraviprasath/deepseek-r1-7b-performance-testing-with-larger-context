# Conclusions

Local LLMs such as DeepSeek-R1:7B are not designed for large, unfiltered
context ingestion.

Key findings:
- Larger context does not improve answer quality
- Instruction-following degrades beyond a threshold
- Chunking or retrieval-based approaches are required

This benchmark highlights the importance of designing prompts and
systems around local model limitations.
